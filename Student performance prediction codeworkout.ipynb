{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58fb1a4-cdb2-4d5b-bf69-c505cf15839b",
   "metadata": {},
   "source": [
    "Overall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b520c573-840e-46f9-a505-d9be04a45142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\784721941.py:5: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>ToolInstances</th>\n",
       "      <th>ServerTimestamp</th>\n",
       "      <th>ServerTimezone</th>\n",
       "      <th>CourseID</th>\n",
       "      <th>CourseSectionID</th>\n",
       "      <th>AssignmentID</th>\n",
       "      <th>ProblemID</th>\n",
       "      <th>CodeStateID</th>\n",
       "      <th>IsEventOrderingConsistent</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Score</th>\n",
       "      <th>Compile.Result</th>\n",
       "      <th>CompileMessageType</th>\n",
       "      <th>CompileMessageData</th>\n",
       "      <th>EventID</th>\n",
       "      <th>ParentEventID</th>\n",
       "      <th>SourceLocation</th>\n",
       "      <th>TermID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119630</td>\n",
       "      <td>00c54f9462673d4c09d2a88121860841</td>\n",
       "      <td>Java 8; CodeWorkout</td>\n",
       "      <td>2019-02-24T05:13:03</td>\n",
       "      <td>UTC</td>\n",
       "      <td>CS 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>439</td>\n",
       "      <td>1</td>\n",
       "      <td>efdf3fae54cdc0a09fb81fcfa365c5f843e837b0</td>\n",
       "      <td>True</td>\n",
       "      <td>Run.Program</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-69176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spring2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119631</td>\n",
       "      <td>00c54f9462673d4c09d2a88121860841</td>\n",
       "      <td>Java 8; CodeWorkout</td>\n",
       "      <td>2019-02-24T05:13:03</td>\n",
       "      <td>UTC</td>\n",
       "      <td>CS 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>439</td>\n",
       "      <td>1</td>\n",
       "      <td>efdf3fae54cdc0a09fb81fcfa365c5f843e837b0</td>\n",
       "      <td>True</td>\n",
       "      <td>Compile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-69177</td>\n",
       "      <td>1-69176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spring2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134330</td>\n",
       "      <td>00c54f9462673d4c09d2a88121860841</td>\n",
       "      <td>Java 8; CodeWorkout</td>\n",
       "      <td>2019-02-24T05:13:33</td>\n",
       "      <td>0</td>\n",
       "      <td>CS 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>79b2bcc8f502e1f7d2d4e83d1894964684c89b85</td>\n",
       "      <td>True</td>\n",
       "      <td>Run.Program</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-68089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spring2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134331</td>\n",
       "      <td>00c54f9462673d4c09d2a88121860841</td>\n",
       "      <td>Java 8; CodeWorkout</td>\n",
       "      <td>2019-02-24T05:13:33</td>\n",
       "      <td>0</td>\n",
       "      <td>CS 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>79b2bcc8f502e1f7d2d4e83d1894964684c89b85</td>\n",
       "      <td>True</td>\n",
       "      <td>Compile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-68090</td>\n",
       "      <td>3-68089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spring2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65666</td>\n",
       "      <td>00c54f9462673d4c09d2a88121860841</td>\n",
       "      <td>Java 8; CodeWorkout</td>\n",
       "      <td>2019-02-24T05:09:54</td>\n",
       "      <td>UTC</td>\n",
       "      <td>CS 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>439</td>\n",
       "      <td>5</td>\n",
       "      <td>2697d299e7c5992f557ce38d8a04345112a11af8</td>\n",
       "      <td>True</td>\n",
       "      <td>Run.Program</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-35681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spring2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561741</th>\n",
       "      <td>458748</td>\n",
       "      <td>ffc3b91c3744d275e99f49e105f016732d694a76314d8c...</td>\n",
       "      <td>Java 8; CodeWorkout</td>\n",
       "      <td>2019-12-02T14:09:56</td>\n",
       "      <td>0</td>\n",
       "      <td>CS 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>502</td>\n",
       "      <td>48</td>\n",
       "      <td>569c90103f63f8fea6a5cac8fbf8bef92f4f4aaa29a9c6...</td>\n",
       "      <td>True</td>\n",
       "      <td>Compile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>458748</td>\n",
       "      <td>458747.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fall2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561742</th>\n",
       "      <td>458749</td>\n",
       "      <td>ffc3b91c3744d275e99f49e105f016732d694a76314d8c...</td>\n",
       "      <td>Java 8; CodeWorkout</td>\n",
       "      <td>2019-12-02T14:10:13</td>\n",
       "      <td>0</td>\n",
       "      <td>CS 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>502</td>\n",
       "      <td>48</td>\n",
       "      <td>379999e4e41a72475cd23de40bd2ec704afd960b1d59eb...</td>\n",
       "      <td>True</td>\n",
       "      <td>Run.Program</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>458749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fall2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561743</th>\n",
       "      <td>458750</td>\n",
       "      <td>ffc3b91c3744d275e99f49e105f016732d694a76314d8c...</td>\n",
       "      <td>Java 8; CodeWorkout</td>\n",
       "      <td>2019-12-02T14:10:13</td>\n",
       "      <td>0</td>\n",
       "      <td>CS 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>502</td>\n",
       "      <td>48</td>\n",
       "      <td>379999e4e41a72475cd23de40bd2ec704afd960b1d59eb...</td>\n",
       "      <td>True</td>\n",
       "      <td>Compile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>458750</td>\n",
       "      <td>458749.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fall2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561744</th>\n",
       "      <td>458751</td>\n",
       "      <td>ffc3b91c3744d275e99f49e105f016732d694a76314d8c...</td>\n",
       "      <td>Java 8; CodeWorkout</td>\n",
       "      <td>2019-12-02T14:10:56</td>\n",
       "      <td>0</td>\n",
       "      <td>CS 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>502</td>\n",
       "      <td>48</td>\n",
       "      <td>dc69e0187b8ab8b4489196195578c86c561dc11938cbc8...</td>\n",
       "      <td>True</td>\n",
       "      <td>Run.Program</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>458751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fall2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561745</th>\n",
       "      <td>458752</td>\n",
       "      <td>ffc3b91c3744d275e99f49e105f016732d694a76314d8c...</td>\n",
       "      <td>Java 8; CodeWorkout</td>\n",
       "      <td>2019-12-02T14:10:56</td>\n",
       "      <td>0</td>\n",
       "      <td>CS 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>502</td>\n",
       "      <td>48</td>\n",
       "      <td>dc69e0187b8ab8b4489196195578c86c561dc11938cbc8...</td>\n",
       "      <td>True</td>\n",
       "      <td>Compile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>458752</td>\n",
       "      <td>458751.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fall2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561746 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order                                          SubjectID  \\\n",
       "0       119630                   00c54f9462673d4c09d2a88121860841   \n",
       "1       119631                   00c54f9462673d4c09d2a88121860841   \n",
       "2       134330                   00c54f9462673d4c09d2a88121860841   \n",
       "3       134331                   00c54f9462673d4c09d2a88121860841   \n",
       "4        65666                   00c54f9462673d4c09d2a88121860841   \n",
       "...        ...                                                ...   \n",
       "561741  458748  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...   \n",
       "561742  458749  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...   \n",
       "561743  458750  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...   \n",
       "561744  458751  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...   \n",
       "561745  458752  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...   \n",
       "\n",
       "              ToolInstances      ServerTimestamp ServerTimezone CourseID  \\\n",
       "0       Java 8; CodeWorkout  2019-02-24T05:13:03            UTC     CS 1   \n",
       "1       Java 8; CodeWorkout  2019-02-24T05:13:03            UTC     CS 1   \n",
       "2       Java 8; CodeWorkout  2019-02-24T05:13:33              0     CS 1   \n",
       "3       Java 8; CodeWorkout  2019-02-24T05:13:33              0     CS 1   \n",
       "4       Java 8; CodeWorkout  2019-02-24T05:09:54            UTC     CS 1   \n",
       "...                     ...                  ...            ...      ...   \n",
       "561741  Java 8; CodeWorkout  2019-12-02T14:09:56              0     CS 1   \n",
       "561742  Java 8; CodeWorkout  2019-12-02T14:10:13              0     CS 1   \n",
       "561743  Java 8; CodeWorkout  2019-12-02T14:10:13              0     CS 1   \n",
       "561744  Java 8; CodeWorkout  2019-12-02T14:10:56              0     CS 1   \n",
       "561745  Java 8; CodeWorkout  2019-12-02T14:10:56              0     CS 1   \n",
       "\n",
       "        CourseSectionID  AssignmentID  ProblemID  \\\n",
       "0                   1.0           439          1   \n",
       "1                   1.0           439          1   \n",
       "2                   1.0           439          3   \n",
       "3                   1.0           439          3   \n",
       "4                   1.0           439          5   \n",
       "...                 ...           ...        ...   \n",
       "561741              NaN           502         48   \n",
       "561742              NaN           502         48   \n",
       "561743              NaN           502         48   \n",
       "561744              NaN           502         48   \n",
       "561745              NaN           502         48   \n",
       "\n",
       "                                              CodeStateID  \\\n",
       "0                efdf3fae54cdc0a09fb81fcfa365c5f843e837b0   \n",
       "1                efdf3fae54cdc0a09fb81fcfa365c5f843e837b0   \n",
       "2                79b2bcc8f502e1f7d2d4e83d1894964684c89b85   \n",
       "3                79b2bcc8f502e1f7d2d4e83d1894964684c89b85   \n",
       "4                2697d299e7c5992f557ce38d8a04345112a11af8   \n",
       "...                                                   ...   \n",
       "561741  569c90103f63f8fea6a5cac8fbf8bef92f4f4aaa29a9c6...   \n",
       "561742  379999e4e41a72475cd23de40bd2ec704afd960b1d59eb...   \n",
       "561743  379999e4e41a72475cd23de40bd2ec704afd960b1d59eb...   \n",
       "561744  dc69e0187b8ab8b4489196195578c86c561dc11938cbc8...   \n",
       "561745  dc69e0187b8ab8b4489196195578c86c561dc11938cbc8...   \n",
       "\n",
       "        IsEventOrderingConsistent    EventType     Score Compile.Result  \\\n",
       "0                            True  Run.Program  1.000000            NaN   \n",
       "1                            True      Compile       NaN        Success   \n",
       "2                            True  Run.Program  1.000000            NaN   \n",
       "3                            True      Compile       NaN        Success   \n",
       "4                            True  Run.Program  0.750000            NaN   \n",
       "...                           ...          ...       ...            ...   \n",
       "561741                       True      Compile       NaN        Success   \n",
       "561742                       True  Run.Program  0.727273            NaN   \n",
       "561743                       True      Compile       NaN        Success   \n",
       "561744                       True  Run.Program  1.000000            NaN   \n",
       "561745                       True      Compile       NaN        Success   \n",
       "\n",
       "       CompileMessageType CompileMessageData  EventID ParentEventID  \\\n",
       "0                     NaN                NaN  1-69176           NaN   \n",
       "1                     NaN                NaN  1-69177       1-69176   \n",
       "2                     NaN                NaN  3-68089           NaN   \n",
       "3                     NaN                NaN  3-68090       3-68089   \n",
       "4                     NaN                NaN  5-35681           NaN   \n",
       "...                   ...                ...      ...           ...   \n",
       "561741                NaN                NaN   458748      458747.0   \n",
       "561742                NaN                NaN   458749           NaN   \n",
       "561743                NaN                NaN   458750      458749.0   \n",
       "561744                NaN                NaN   458751           NaN   \n",
       "561745                NaN                NaN   458752      458751.0   \n",
       "\n",
       "       SourceLocation      TermID  \n",
       "0                 NaN  spring2019  \n",
       "1                 NaN  spring2019  \n",
       "2                 NaN  spring2019  \n",
       "3                 NaN  spring2019  \n",
       "4                 NaN  spring2019  \n",
       "...               ...         ...  \n",
       "561741            NaN    fall2019  \n",
       "561742            NaN    fall2019  \n",
       "561743            NaN    fall2019  \n",
       "561744            NaN    fall2019  \n",
       "561745            NaN    fall2019  \n",
       "\n",
       "[561746 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "file_path = 'C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38bfee6-1731-48aa-a35a-145936a6f66e",
   "metadata": {},
   "source": [
    "##### time spent #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ce3572-08cc-45b2-9de1-90105cf6f96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\1758792378.py:5: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               SubjectID  AssignmentID  \\\n",
      "0      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "1      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "2      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "3      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "4      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "...                                                  ...           ...   \n",
      "40206  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40207  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40208  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40209  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40210  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "       ProblemID      time  \n",
      "0              1  00:00:00  \n",
      "1              3  00:06:51  \n",
      "2              5  00:00:40  \n",
      "3             12  00:00:00  \n",
      "4             13  00:07:35  \n",
      "...          ...       ...  \n",
      "40206         64  00:00:17  \n",
      "40207         70  00:17:30  \n",
      "40208         71  00:04:48  \n",
      "40209        112  00:00:15  \n",
      "40210        118  00:00:27  \n",
      "\n",
      "[40211 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "file_path = 'C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'ServerTimestamp' to datetime format\n",
    "df['ServerTimestamp'] = pd.to_datetime(df['ServerTimestamp'])\n",
    "\n",
    "# Split the 'ServerTimestamp' into 'Date' and 'Time'\n",
    "df['Date'] = df['ServerTimestamp'].dt.date\n",
    "df['Time'] = df['ServerTimestamp'].dt.time\n",
    "\n",
    "# Group by 'SubjectID', 'AssignmentID', and calculate total time\n",
    "df_grouped = df.groupby(['SubjectID', 'AssignmentID','ProblemID']).agg(\n",
    "    total_time=('ServerTimestamp', lambda x: (x.max() - x.min()).total_seconds())\n",
    ").reset_index()\n",
    "\n",
    "# Convert total time to timedelta\n",
    "df_grouped['time'] = pd.to_timedelta(df_grouped['total_time'], unit='s')\n",
    "\n",
    "# Drop only the 'total_time' column\n",
    "df_grouped = df_grouped.drop(['total_time'], axis=1)\n",
    "\n",
    "# Display the result with only the time part\n",
    "df_grouped['time'] = df_grouped['time'].astype(str).str.split().str[-1]\n",
    "df_grouped.to_csv('timespent2.csv',index=False)\n",
    "print(df_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784f3337-ab63-4c46-b1b1-1df47b5df069",
   "metadata": {},
   "source": [
    "##### valid #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe20218-90ca-4003-ba27-63e8dfc1fb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\4047906011.py:4: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_dataset = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               SubjectID  AssignmentID  \\\n",
      "0      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "1      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "2      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "3      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "4      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "...                                                  ...           ...   \n",
      "40206  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40207  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40208  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40209  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40210  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "       ProblemID  AttemptCount  \n",
      "0              1             2  \n",
      "1              3             9  \n",
      "2              5             8  \n",
      "3             12             2  \n",
      "4             13            49  \n",
      "...          ...           ...  \n",
      "40206         64             5  \n",
      "40207         70            18  \n",
      "40208         71            11  \n",
      "40209        112             5  \n",
      "40210        118             4  \n",
      "\n",
      "[40211 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the original CSV file\n",
    "original_dataset = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv')\n",
    "\n",
    "# Specify the columns you want to keep in the new dataset\n",
    "selected_columns = ['SubjectID', 'AssignmentID', 'ProblemID']\n",
    "\n",
    "# Create a new dataset with only the selected columns\n",
    "new_dataset = original_dataset[selected_columns]\n",
    "\n",
    "# Group by SubjectID, AssignmentID, and ProblemID, and count the occurrences\n",
    "result = new_dataset.groupby(['SubjectID', 'AssignmentID', 'ProblemID']).size().reset_index(name='AttemptCount')\n",
    "result.to_csv('vaild2.csv',index=False)\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c4670-ac0e-4dda-8254-a5c788dc141d",
   "metadata": {},
   "source": [
    "###### Correct Sub #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a9e967-122d-483b-ba4f-ab6ee44a7d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\1594774441.py:4: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               SubjectID  AssignmentID  \\\n",
      "0      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "1      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "2      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "3      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "4      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "...                                                  ...           ...   \n",
      "37603  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "37604  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "37605  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "37606  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "37607  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "       ProblemID  CorrectSubmissionCount  \n",
      "0              1                       1  \n",
      "1              3                       1  \n",
      "2              5                       1  \n",
      "3             12                       1  \n",
      "4             13                       1  \n",
      "...          ...                     ...  \n",
      "37603         64                       1  \n",
      "37604         70                       1  \n",
      "37605         71                       3  \n",
      "37606        112                       1  \n",
      "37607        118                       1  \n",
      "\n",
      "[37608 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv')\n",
    "\n",
    "# Filter rows where the \"Score\" column is equal to 1\n",
    "correct_submissions = df[df['Score'] == 1]\n",
    "\n",
    "# Group by 'SubjectID' and 'AssignmentID', and count the number of correct submissions\n",
    "submission_counts = correct_submissions.groupby(['SubjectID', 'AssignmentID','ProblemID']).size().reset_index(name='CorrectSubmissionCount')\n",
    "submission_counts.to_csv('correctsub2.csv',index=False)\n",
    "# Display the result\n",
    "print(submission_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ce31f-fbcd-424d-80b1-a5dcec8c9c6c",
   "metadata": {},
   "source": [
    "###### Incorrect Sub ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b0b67b-d8b0-4d4d-a113-8f1ff42f56ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\3547722248.py:4: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv')  # Replace 'your_file.csv' with the actual file path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                SubjectID  AssignmentID  \\\n",
      "0                        00c54f9462673d4c09d2a88121860841           439   \n",
      "1                        00c54f9462673d4c09d2a88121860841           439   \n",
      "2                        00c54f9462673d4c09d2a88121860841           439   \n",
      "3                        00c54f9462673d4c09d2a88121860841           439   \n",
      "4                        00c54f9462673d4c09d2a88121860841           439   \n",
      "...                                                   ...           ...   \n",
      "561741  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561742  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561743  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561744  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561745  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "        ProblemID     Score  \n",
      "0               1  1.000000  \n",
      "1               1       NaN  \n",
      "2               3  1.000000  \n",
      "3               3       NaN  \n",
      "4               5  0.750000  \n",
      "...           ...       ...  \n",
      "561741         48       NaN  \n",
      "561742         48  0.727273  \n",
      "561743         48       NaN  \n",
      "561744         48  1.000000  \n",
      "561745         48       NaN  \n",
      "\n",
      "[561746 rows x 4 columns]\n",
      "                                               SubjectID  AssignmentID  \\\n",
      "0      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "1      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "2      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "3      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "4      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "...                                                  ...           ...   \n",
      "25452  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "25453  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "25454  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "25455  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "25456  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "       ProblemID  CountScoreLessThan1  \n",
      "0              3                    3  \n",
      "1              5                    2  \n",
      "2             13                    5  \n",
      "3            232                    2  \n",
      "4            233                    6  \n",
      "...          ...                  ...  \n",
      "25452         64                    1  \n",
      "25453         70                    8  \n",
      "25454         71                    2  \n",
      "25455        112                    1  \n",
      "25456        118                    1  \n",
      "\n",
      "[25457 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv')  # Replace 'your_file.csv' with the actual file path\n",
    "\n",
    "# Specify the columns you want to keep in the new dataset\n",
    "selected_columns = ['SubjectID', 'AssignmentID','ProblemID', 'Score']\n",
    "\n",
    "# Create a new dataset with only the selected columns\n",
    "new_dataset = df[selected_columns]\n",
    "\n",
    "print(new_dataset)\n",
    "\n",
    "# Filter rows where the \"Score\" column is less than 1 (including 0)\n",
    "filtered_df = df[df['Score'] < 1]\n",
    "\n",
    "# Count the occurrences for each unique combination of SubjectID and AssignmentID\n",
    "result = filtered_df.groupby(['SubjectID', 'AssignmentID','ProblemID']).size().reset_index(name='CountScoreLessThan1')\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e84fd8c-1d97-4bad-985a-1ad5400253e7",
   "metadata": {},
   "source": [
    "###### Compile Error ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d446806-26ee-4560-900a-6a901cda111b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\3674769963.py:4: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                SubjectID  AssignmentID  \\\n",
      "0                        00c54f9462673d4c09d2a88121860841           439   \n",
      "1                        00c54f9462673d4c09d2a88121860841           439   \n",
      "2                        00c54f9462673d4c09d2a88121860841           439   \n",
      "3                        00c54f9462673d4c09d2a88121860841           439   \n",
      "4                        00c54f9462673d4c09d2a88121860841           439   \n",
      "...                                                   ...           ...   \n",
      "561741  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561742  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561743  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561744  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561745  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "        ProblemID    EventType Compile.Result  \n",
      "0               1  Run.Program            NaN  \n",
      "1               1      Compile        Success  \n",
      "2               3  Run.Program            NaN  \n",
      "3               3      Compile        Success  \n",
      "4               5  Run.Program            NaN  \n",
      "...           ...          ...            ...  \n",
      "561741         48      Compile        Success  \n",
      "561742         48  Run.Program            NaN  \n",
      "561743         48      Compile        Success  \n",
      "561744         48  Run.Program            NaN  \n",
      "561745         48      Compile        Success  \n",
      "\n",
      "[561746 rows x 5 columns]\n",
      "                                               SubjectID  AssignmentID  \\\n",
      "0      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "1      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "2      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "3      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "4      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "...                                                  ...           ...   \n",
      "20999  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "21000  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "21001  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "21002  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "21003  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "       ProblemID  CountCompileError  \n",
      "0              3                  1  \n",
      "1              5                  2  \n",
      "2             13                 37  \n",
      "3            232                 15  \n",
      "4            233                  6  \n",
      "...          ...                ...  \n",
      "20999         51                  1  \n",
      "21000         56                  1  \n",
      "21001         64                  1  \n",
      "21002         71                  1  \n",
      "21003        112                  1  \n",
      "\n",
      "[21004 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv')\n",
    "\n",
    "# Specify the columns you want to keep in the new dataset\n",
    "selected_columns = ['SubjectID', 'AssignmentID', 'ProblemID','EventType','Compile.Result']\n",
    "\n",
    "# Create a new dataset with only the selected columns\n",
    "new_dataset = df[selected_columns]\n",
    "print(new_dataset)\n",
    "\n",
    "# Filter rows where EventType is \"Compile\" and Compile.Result is \"Success\"\n",
    "compile_error_df = df[df['EventType'] == 'Compile.Error']\n",
    "\n",
    "# Count the occurrences for each unique combination of SubjectID and AssignmentID\n",
    "result = compile_error_df.groupby(['SubjectID', 'AssignmentID','ProblemID']).size().reset_index(name='CountCompileError')\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee0807-3a20-400a-9fbd-4d50d0951c1f",
   "metadata": {},
   "source": [
    "######  Edit Distance ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ffcddc-c003-4ea3-a619-ef80aa142dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\3763014376.py:8: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                SubjectID  AssignmentID  \\\n",
      "0       00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "1       00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "2       00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "3       00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "4       00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "...                                                   ...           ...   \n",
      "195200  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "195201  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "195202  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "195203  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "195204  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "        ProblemID                                        CodeStateID  \\\n",
      "0               1  5c3b1a18d738139379a040695b382bb8a44f0be2302fa7...   \n",
      "1               3  3a5e12260a96cf9c47fba8f2ca8a9b6a16e799a5dcd372...   \n",
      "2               3  53e05b92cf3e024e5b8c4858d8e02ccd724e1283d53cde...   \n",
      "3               3  7451e25234b583a1790f273fe2a3a07843369046e2b61f...   \n",
      "4               3  c9320c47b7044259c7d086723ea712c4b00fa2ccb15461...   \n",
      "...           ...                                                ...   \n",
      "195200         71  cd6d9e1d530ac7ff40a8413570da8859b02abe2de415e8...   \n",
      "195201        112  9ef2cfa57a0d812fd9a6fb04ed0397985aaee5a8ddfbc3...   \n",
      "195202        112  add860149e169c4e0ef359e8523a475bff1cb35185d799...   \n",
      "195203        118  38e11aa1c182ae86953bcf1b435fd1a7e9decdb7434aee...   \n",
      "195204        118  e93270dbbeb99d37024546a81c424ca7ac89255c5ab3d4...   \n",
      "\n",
      "        Occurrences  \n",
      "0                 2  \n",
      "1                 2  \n",
      "2                 3  \n",
      "3                 2  \n",
      "4                 2  \n",
      "...             ...  \n",
      "195200            2  \n",
      "195201            3  \n",
      "195202            2  \n",
      "195203            2  \n",
      "195204            2  \n",
      "\n",
      "[195205 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a CSV file named 'your_dataset.csv'\n",
    "# Replace 'your_dataset.csv' with the actual path to your CSV file\n",
    "csv_file_path = 'C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Group by unique combinations and count occurrences\n",
    "occurrences_df = df.groupby(['SubjectID', 'AssignmentID', 'ProblemID', 'CodeStateID']).size().reset_index(name='Occurrences')\n",
    "\n",
    "\n",
    "# Display the result\n",
    "print(occurrences_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aac23c5b-80bc-472c-9bfb-a46fa68fc2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to finaleditdistance2.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from Levenshtein import distance\n",
    "\n",
    "# Read data from CSV file\n",
    "csv_file_path = 'C:/Users/bala4/OneDrive/Pictures/student prediction/editdistance.csv'  # Replace with the path to your CSV file\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(csv_file_path, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "\n",
    "# Find unique combinations of SubjectID, AssignmentID, and ProblemID\n",
    "unique_combinations = set((row[\"SubjectID\"], row[\"AssignmentID\"], row[\"ProblemID\"]) for row in data)\n",
    "\n",
    "# Open output CSV file for writing\n",
    "with open(output_csv_file_path, 'w', newline='') as output_csvfile:\n",
    "    fieldnames = [\"SubjectID\", \"AssignmentID\", \"ProblemID\", \"OverallEditDistance\"]\n",
    "    writer = csv.DictWriter(output_csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Iterate through unique combinations\n",
    "    for combination in unique_combinations:\n",
    "        target_subject_id, target_assignment_id, target_problem_id = combination\n",
    "\n",
    "        # Filter rows for the specific combination\n",
    "        target_rows = [row for row in data if row[\"SubjectID\"] == target_subject_id\n",
    "                       and row[\"AssignmentID\"] == target_assignment_id\n",
    "                       and row[\"ProblemID\"] == target_problem_id]\n",
    "\n",
    "        # Extract CodeStateIDs for the specific combination\n",
    "        codestate_ids = [row[\"CodeStateID\"] for row in target_rows]\n",
    "\n",
    "        # Calculate overall edit distance between different CodeStateIDs\n",
    "        overall_distance = 0\n",
    "\n",
    "        for i in range(len(codestate_ids)):\n",
    "            for j in range(i + 1, len(codestate_ids)):\n",
    "                id1, id2 = codestate_ids[i], codestate_ids[j]\n",
    "                overall_distance += distance(id1, id2)\n",
    "\n",
    "        # Write the result to the output CSV file\n",
    "        writer.writerow({\n",
    "            \"SubjectID\": target_subject_id,\n",
    "            \"AssignmentID\": target_assignment_id,\n",
    "            \"ProblemID\": target_problem_id,\n",
    "            \"OverallEditDistance\": overall_distance\n",
    "        })\n",
    "\n",
    "print(f\"Results written to {output_csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc7ab2-5dcb-44c9-99a6-29aa0f53460e",
   "metadata": {},
   "source": [
    "######  Score ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0228c301-0d07-4b96-a0bb-279e215a7acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\1657461266.py:7: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                SubjectID  AssignmentID  \\\n",
      "0                        00c54f9462673d4c09d2a88121860841           439   \n",
      "1                        00c54f9462673d4c09d2a88121860841           439   \n",
      "2                        00c54f9462673d4c09d2a88121860841           439   \n",
      "3                        00c54f9462673d4c09d2a88121860841           439   \n",
      "4                        00c54f9462673d4c09d2a88121860841           439   \n",
      "...                                                   ...           ...   \n",
      "561741  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561742  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561743  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561744  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "561745  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "        ProblemID     Score  \n",
      "0               1  1.000000  \n",
      "1               1       NaN  \n",
      "2               3  1.000000  \n",
      "3               3       NaN  \n",
      "4               5  0.750000  \n",
      "...           ...       ...  \n",
      "561741         48       NaN  \n",
      "561742         48  0.727273  \n",
      "561743         48       NaN  \n",
      "561744         48  1.000000  \n",
      "561745         48       NaN  \n",
      "\n",
      "[561746 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_input_file.csv' with the actual filename\n",
    "input_file_path = 'C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# List of columns to be removed\n",
    "columns_to_remove = [\"Order\", \"ToolInstances\", \"ServerTimestamp\",\"ServerTimezone\",\"CourseID\",\"CourseSectionID\",\"IsEventOrderingConsistent\",\"EventType\",\"CodeStateID\",\n",
    "                    \"Compile.Result\",\"CompileMessageType\",\"CompileMessageData\",\"EventID\",\"ParentEventID\",\"SourceLocation\",\"TermID\"]  # Replace with the columns you want to remove\n",
    "\n",
    "# Remove specified columns\n",
    "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5189fd2a-a67e-466f-a6a3-6f480b71cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             SubjectID  ScoreCount\n",
      "0    00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...         248\n",
      "1                     00c54f9462673d4c09d2a88121860841          55\n",
      "2    014604ba54339d4b1266cf78e125053a5ac11dd861ef3c...         281\n",
      "3    01e96e066eff2e82627dac0493737be2de9bd2f50d6d49...         166\n",
      "4    03000c72d4dd6a4be44ffc175dec5d9a15a83a2f8073b0...         360\n",
      "..                                                 ...         ...\n",
      "914  ff02364c8aab08a51916bd6a58bf7337b5d60939ee9b53...         372\n",
      "915  ff4cfd98fc176f36fa99b2bc839990d2fd13de4e59b5c4...         216\n",
      "916  ff86d28801139f82f29ac25c715647674d50977478b8d8...         167\n",
      "917                   ffb72475a81de0e95b910ffad039f5c2         227\n",
      "918  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...         182\n",
      "\n",
      "[919 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_dataset.csv' with the actual file name\n",
    "df = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/orginalscore.csv')\n",
    "\n",
    "# Group by 'SubjectID' and count the scores\n",
    "subject_scores_count = df.groupby('SubjectID')['Score'].count().reset_index(name='ScoreCount')\n",
    "\n",
    "# Display the result\n",
    "print(subject_scores_count)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b48c340-8a4d-4385-965e-4e928444e93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             SubjectID  ScoreCount  \\\n",
      "0    00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...         248   \n",
      "1                     00c54f9462673d4c09d2a88121860841          55   \n",
      "2    014604ba54339d4b1266cf78e125053a5ac11dd861ef3c...         281   \n",
      "3    01e96e066eff2e82627dac0493737be2de9bd2f50d6d49...         166   \n",
      "4    03000c72d4dd6a4be44ffc175dec5d9a15a83a2f8073b0...         360   \n",
      "..                                                 ...         ...   \n",
      "914  ff02364c8aab08a51916bd6a58bf7337b5d60939ee9b53...         372   \n",
      "915  ff4cfd98fc176f36fa99b2bc839990d2fd13de4e59b5c4...         216   \n",
      "916  ff86d28801139f82f29ac25c715647674d50977478b8d8...         167   \n",
      "917                   ffb72475a81de0e95b910ffad039f5c2         227   \n",
      "918  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...         182   \n",
      "\n",
      "     NormalizedScore  \n",
      "0           0.221525  \n",
      "1           0.048430  \n",
      "2           0.251121  \n",
      "3           0.147982  \n",
      "4           0.321973  \n",
      "..               ...  \n",
      "914         0.332735  \n",
      "915         0.192825  \n",
      "916         0.148879  \n",
      "917         0.202691  \n",
      "918         0.162332  \n",
      "\n",
      "[919 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_dataset.csv' with the actual file name\n",
    "df = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/preprocess score.csv')\n",
    "\n",
    "# Assuming 'CountScore' is the column you want to normalize\n",
    "min_score = df['ScoreCount'].min()\n",
    "max_score = df['ScoreCount'].max()\n",
    "df['NormalizedScore'] = (df['ScoreCount'] - min_score) / (max_score - min_score)\n",
    "\n",
    "\n",
    "\n",
    "# Display the result\n",
    "print(df[['SubjectID', 'ScoreCount', 'NormalizedScore']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795dd64f-e579-4114-aa05-9cb1ac8a070d",
   "metadata": {},
   "source": [
    "##### Merge Dataset ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b862f4c3-8a10-43bc-833a-502393d15672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\1085218806.py:4: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_dataset = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv')\n",
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\1085218806.py:35: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\bala4\\AppData\\Local\\Temp\\ipykernel_12264\\1085218806.py:53: DtypeWarning: Columns (4,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               SubjectID  AssignmentID  \\\n",
      "0      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "1      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "2      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "3      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "4      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "...                                                  ...           ...   \n",
      "40206  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40207  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40208  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40209  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40210  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "       ProblemID  AttemptCount  CountScoreLessThan1  CorrectSubmissionCount  \\\n",
      "0              1             2                  NaN                     1.0   \n",
      "1              3             9                  3.0                     1.0   \n",
      "2              5             8                  2.0                     1.0   \n",
      "3             12             2                  NaN                     1.0   \n",
      "4             13            49                  5.0                     1.0   \n",
      "...          ...           ...                  ...                     ...   \n",
      "40206         64             5                  1.0                     1.0   \n",
      "40207         70            18                  8.0                     1.0   \n",
      "40208         71            11                  2.0                     3.0   \n",
      "40209        112             5                  1.0                     1.0   \n",
      "40210        118             4                  1.0                     1.0   \n",
      "\n",
      "       CountCompileError      time  \n",
      "0                    NaN  00:00:00  \n",
      "1                    1.0  00:06:51  \n",
      "2                    2.0  00:00:40  \n",
      "3                    NaN  00:00:00  \n",
      "4                    5.0  00:07:35  \n",
      "...                  ...       ...  \n",
      "40206                1.0  00:00:17  \n",
      "40207                NaN  00:17:30  \n",
      "40208                1.0  00:04:48  \n",
      "40209                1.0  00:00:15  \n",
      "40210                NaN  00:00:27  \n",
      "\n",
      "[40211 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the original CSV file\n",
    "original_dataset = pd.read_csv('C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv')\n",
    "\n",
    "# Specify the columns you want to keep for attempts\n",
    "selected_columns_attempts = ['SubjectID', 'AssignmentID', 'ProblemID']\n",
    "\n",
    "# Create a new dataset with only the selected columns for attempts\n",
    "new_dataset_attempts = original_dataset[selected_columns_attempts]\n",
    "\n",
    "# Group by SubjectID, AssignmentID, and ProblemID, and count the occurrences for attempts\n",
    "result_attempts = new_dataset_attempts.groupby(['SubjectID', 'AssignmentID', 'ProblemID']).size().reset_index(name='AttemptCount')\n",
    "\n",
    "# Filter rows where the \"Score\" column is less than 1 (including 0) for correct submissions\n",
    "filtered_df = original_dataset[original_dataset['Score'] < 1]\n",
    "\n",
    "# Count the occurrences for each unique combination of SubjectID, AssignmentID, and ProblemID for correct submissions\n",
    "result_correct_submissions = filtered_df.groupby(['SubjectID', 'AssignmentID', 'ProblemID']).size().reset_index(name='CountScoreLessThan1')\n",
    "\n",
    "# Merge the results on the common columns for attempts and correct submissions\n",
    "merged_result = pd.merge(result_attempts, result_correct_submissions, how='left', on=['SubjectID', 'AssignmentID', 'ProblemID'])\n",
    "\n",
    "# Filter rows where the \"Score\" column is equal to 1 for correct submissions\n",
    "correct_submissions = original_dataset[original_dataset['Score'] == 1]\n",
    "\n",
    "# Group by 'SubjectID', 'AssignmentID', and 'ProblemID', and count the number of correct submissions\n",
    "submission_counts = correct_submissions.groupby(['SubjectID', 'AssignmentID', 'ProblemID']).size().reset_index(name='CorrectSubmissionCount')\n",
    "\n",
    "# Merge the results on the common columns for attempts, correct submissions, and overall counts\n",
    "final_merged_result = pd.merge(merged_result, submission_counts, how='left', on=['SubjectID', 'AssignmentID', 'ProblemID'])\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "file_path = 'C:/Users/bala4/OneDrive/Pictures/student prediction/merged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Specify the columns you want to keep in the new dataset\n",
    "selected_columns_compile = ['SubjectID', 'AssignmentID', 'ProblemID', 'EventType', 'Compile.Result']\n",
    "\n",
    "# Create a new dataset with only the selected columns for compile errors\n",
    "new_dataset_compile = df[selected_columns_compile]\n",
    "\n",
    "# Filter rows where EventType is \"Compile\" and Compile.Result is \"Error\"\n",
    "compile_error_df = new_dataset_compile[(new_dataset_compile['EventType'] == 'Compile') & (new_dataset_compile['Compile.Result'] == 'Error')]\n",
    "\n",
    "# Count the occurrences for each unique combination of SubjectID, AssignmentID, and ProblemID for compile errors\n",
    "result_compile_errors = compile_error_df.groupby(['SubjectID', 'AssignmentID', 'ProblemID']).size().reset_index(name='CountCompileError')\n",
    "\n",
    "# Merge the results on the common columns for attempts, correct submissions, compile errors, and overall counts\n",
    "final_merged_result = pd.merge(final_merged_result, result_compile_errors, how='left', on=['SubjectID', 'AssignmentID', 'ProblemID'])\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'ServerTimestamp' to datetime format\n",
    "df['ServerTimestamp'] = pd.to_datetime(df['ServerTimestamp'])\n",
    "\n",
    "# Split the 'ServerTimestamp' into 'Date' and 'Time'\n",
    "df['Date'] = df['ServerTimestamp'].dt.date\n",
    "df['Time'] = df['ServerTimestamp'].dt.time\n",
    "\n",
    "# Group by 'SubjectID', 'AssignmentID', and calculate total time\n",
    "df_grouped = df.groupby(['SubjectID', 'AssignmentID','ProblemID']).agg(\n",
    "    total_time=('ServerTimestamp', lambda x: (x.max() - x.min()).total_seconds())\n",
    ").reset_index()\n",
    "\n",
    "# Convert total time to timedelta\n",
    "df_grouped['time'] = pd.to_timedelta(df_grouped['total_time'], unit='s')\n",
    "\n",
    "# Drop only the 'total_time' column\n",
    "df_grouped = df_grouped.drop(['total_time'], axis=1)\n",
    "\n",
    "# Display the result with only the time part\n",
    "df_grouped['time'] = df_grouped['time'].astype(str).str.split().str[-1]\n",
    "\n",
    "# Merge the results on the common columns for attempts, correct submissions, compile errors, overall counts, and time-related information\n",
    "final_merged_result = pd.merge(final_merged_result, df_grouped, how='left', on=['SubjectID', 'AssignmentID', 'ProblemID'])\n",
    "\n",
    "# Display the final merged result\n",
    "print(final_merged_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd1ad3b1-d665-497f-b47f-683ce8e6d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               SubjectID  AssignmentID  \\\n",
      "0      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "1      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "2      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "3      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "4      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "...                                                  ...           ...   \n",
      "40206  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40207  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40208  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40209  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40210  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "       ProblemID  AttemptCount  CountScoreLessThan1  CorrectSubmissionCount  \\\n",
      "0              1             2                  NaN                     1.0   \n",
      "1              3             9                  3.0                     1.0   \n",
      "2              5             8                  2.0                     1.0   \n",
      "3             12             2                  NaN                     1.0   \n",
      "4             13            49                  5.0                     1.0   \n",
      "...          ...           ...                  ...                     ...   \n",
      "40206         64             5                  1.0                     1.0   \n",
      "40207         70            18                  8.0                     1.0   \n",
      "40208         71            11                  2.0                     3.0   \n",
      "40209        112             5                  1.0                     1.0   \n",
      "40210        118             4                  1.0                     1.0   \n",
      "\n",
      "       CountCompileError      time  OverallEditDistance  \n",
      "0                    NaN  00:00:00                    0  \n",
      "1                    1.0  00:06:51                  327  \n",
      "2                    2.0  00:00:40                  168  \n",
      "3                    NaN  00:00:00                    0  \n",
      "4                    5.0  00:07:35                  812  \n",
      "...                  ...       ...                  ...  \n",
      "40206                1.0  00:00:17                   57  \n",
      "40207                NaN  00:17:30                 1996  \n",
      "40208                1.0  00:04:48                  551  \n",
      "40209                1.0  00:00:15                   56  \n",
      "40210                NaN  00:00:27                   56  \n",
      "\n",
      "[40211 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file into a DataFrame\n",
    "df1 = pd.read_csv('over.csv')\n",
    "\n",
    "# Load the second CSV file into a DataFrame\n",
    "df2 = pd.read_csv(\"C:/Users/bala4/OneDrive/Pictures/student prediction/finaleditdistance2.csv\")\n",
    "\n",
    "# Specify the common columns on which you want to merge the datasets\n",
    "common_columns = ['SubjectID', 'AssignmentID', 'ProblemID']\n",
    "\n",
    "# Merge the datasets using the specified common columns\n",
    "merged_df = pd.merge(df1, df2, on=common_columns, how='inner')  # You can use 'left', 'right', or 'outer' as well\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93c5019b-60c9-4c55-88cb-f541bbc606ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               SubjectID  AssignmentID  \\\n",
      "0      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "1      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "2      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "3      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "4      00358c94503a8d9e6869efc6e5cdb0e1c8e9eb39b1fd46...           439   \n",
      "...                                                  ...           ...   \n",
      "40206  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40207  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40208  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40209  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "40210  ffc3b91c3744d275e99f49e105f016732d694a76314d8c...           502   \n",
      "\n",
      "       ProblemID  AttemptCount  CountScoreLessThan1  CorrectSubmissionCount  \\\n",
      "0              1             2                  NaN                     1.0   \n",
      "1              3             9                  3.0                     1.0   \n",
      "2              5             8                  2.0                     1.0   \n",
      "3             12             2                  NaN                     1.0   \n",
      "4             13            49                  5.0                     1.0   \n",
      "...          ...           ...                  ...                     ...   \n",
      "40206         64             5                  1.0                     1.0   \n",
      "40207         70            18                  8.0                     1.0   \n",
      "40208         71            11                  2.0                     3.0   \n",
      "40209        112             5                  1.0                     1.0   \n",
      "40210        118             4                  1.0                     1.0   \n",
      "\n",
      "       CountCompileError      time  OverallEditDistance  ScoreCount  \\\n",
      "0                    NaN  00:00:00                    0         248   \n",
      "1                    1.0  00:06:51                  327         248   \n",
      "2                    2.0  00:00:40                  168         248   \n",
      "3                    NaN  00:00:00                    0         248   \n",
      "4                    5.0  00:07:35                  812         248   \n",
      "...                  ...       ...                  ...         ...   \n",
      "40206                1.0  00:00:17                   57         182   \n",
      "40207                NaN  00:17:30                 1996         182   \n",
      "40208                1.0  00:04:48                  551         182   \n",
      "40209                1.0  00:00:15                   56         182   \n",
      "40210                NaN  00:00:27                   56         182   \n",
      "\n",
      "       NormalizedScore  \n",
      "0             0.221525  \n",
      "1             0.221525  \n",
      "2             0.221525  \n",
      "3             0.221525  \n",
      "4             0.221525  \n",
      "...                ...  \n",
      "40206         0.162332  \n",
      "40207         0.162332  \n",
      "40208         0.162332  \n",
      "40209         0.162332  \n",
      "40210         0.162332  \n",
      "\n",
      "[40211 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file into a DataFrame\n",
    "df1 = pd.read_csv('overall,finall.csv')\n",
    "\n",
    "# Load the second CSV file into a DataFrame\n",
    "df2 = pd.read_csv(\"C:/Users/bala4/OneDrive/Pictures/student prediction/score_normalized.csv\")\n",
    "\n",
    "# Specify the common columns on which you want to merge the datasets\n",
    "common_columns = ['SubjectID']\n",
    "\n",
    "# Merge the datasets using the specified common columns\n",
    "merged_df = pd.merge(df1, df2, on=common_columns, how='outer')  # You can use 'left', 'right', or 'outer' as well\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8199fe10-a42b-4c42-bc42-9efed3cefb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40211 entries, 0 to 40210\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   SubjectID     40211 non-null  object \n",
      " 1   vaild         40211 non-null  int64  \n",
      " 2   incorrectsub  25457 non-null  float64\n",
      " 3   correctsub    37608 non-null  float64\n",
      " 4   compileerror  21004 non-null  float64\n",
      " 5   timespent     40211 non-null  float64\n",
      " 6   editdistance  40211 non-null  int64  \n",
      " 7   score         40211 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from CSV file\n",
    "file_path = \"C:/Users/bala4/OneDrive/Pictures/student prediction/overall preprocessing.csv\"  # Replace with the path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "152afe84-8768-427e-a2a8-e9cdbdf924e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>vaild</th>\n",
       "      <th>incorrectsub</th>\n",
       "      <th>correctsub</th>\n",
       "      <th>compileerror</th>\n",
       "      <th>timespent</th>\n",
       "      <th>editdistance</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40206</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40207</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40208</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40209</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40210</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40211 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SubjectID  vaild  incorrectsub  correctsub  compileerror  timespent  \\\n",
       "0          False  False          True       False          True      False   \n",
       "1          False  False         False       False         False      False   \n",
       "2          False  False         False       False         False      False   \n",
       "3          False  False          True       False          True      False   \n",
       "4          False  False         False       False         False      False   \n",
       "...          ...    ...           ...         ...           ...        ...   \n",
       "40206      False  False         False       False         False      False   \n",
       "40207      False  False         False       False          True      False   \n",
       "40208      False  False         False       False         False      False   \n",
       "40209      False  False         False       False         False      False   \n",
       "40210      False  False         False       False          True      False   \n",
       "\n",
       "       editdistance  score  \n",
       "0             False  False  \n",
       "1             False  False  \n",
       "2             False  False  \n",
       "3             False  False  \n",
       "4             False  False  \n",
       "...             ...    ...  \n",
       "40206         False  False  \n",
       "40207         False  False  \n",
       "40208         False  False  \n",
       "40209         False  False  \n",
       "40210         False  False  \n",
       "\n",
       "[40211 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f88b8a3-c812-4937-b8c4-c3b749e78152",
   "metadata": {},
   "source": [
    "Agument Stacking Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270a5595-9f57-45a5-84ca-540a79f1cb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.00\n",
      "Mean Absolute Error: 0.04\n",
      "R-Squared: 0.72\n",
      "Explained Variance Score: 0.72\n",
      "Median Absolute Error: 0.01\n",
      "Root Mean Squared Error: 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, median_absolute_error\n",
    "\n",
    "# Load data from CSV file\n",
    "file_path = 'agument noise1.csv'  # Replace with the path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Manually specify features (X) and labels (y)\n",
    "X = df[['vaild', 'correctsub', 'incorrectsub', 'compileerror', 'timespent', 'editdistance']]\n",
    "y = df['score']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=20)\n",
    "\n",
    "# Identify and handle NaN values (imputation)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Base Models for Regression\n",
    "base_models = [\n",
    "    ('ExtraTrees', ExtraTreesRegressor(n_estimators=100, random_state=42)),\n",
    "    ('XGBoost', XGBRegressor(random_state=20)),\n",
    "    ('MLP', MLPRegressor(random_state=20))\n",
    "]\n",
    "\n",
    "# Meta-Model for Regression\n",
    "meta_model = RandomForestRegressor(n_estimators=100, random_state=20)\n",
    "\n",
    "# Stacking Regressor\n",
    "stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=meta_model, cv=10)\n",
    "\n",
    "# Fit the model on the imputed data\n",
    "stacking_regressor.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict and Evaluate\n",
    "stacking_predictions = stacking_regressor.predict(X_test_imputed)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the performance using Mean Squared Error for regression\n",
    "mse = mean_squared_error(y_test, stacking_predictions)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "\n",
    "# Evaluate other performance metrics\n",
    "mae = mean_absolute_error(y_test, stacking_predictions)\n",
    "print(f'Mean Absolute Error: {mae:.2f}')\n",
    "\n",
    "r2 = r2_score(y_test, stacking_predictions)\n",
    "print(f'R-Squared: {r2:.2f}')\n",
    "\n",
    "evs = explained_variance_score(y_test, stacking_predictions)\n",
    "print(f'Explained Variance Score: {evs:.2f}')\n",
    "\n",
    "medae = median_absolute_error(y_test, stacking_predictions)\n",
    "print(f'Median Absolute Error: {medae:.2f}')\n",
    "\n",
    "# Evaluate the performance using Root Mean Squared Error for regression\n",
    "rmse = mean_squared_error(y_test, stacking_predictions, squared=False)\n",
    "print(f'Root Mean Squared Error: {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc44269-32d1-4f9d-85d8-9b29ca3587dc",
   "metadata": {},
   "source": [
    "Orginal Skacked Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25cbd0d2-00d8-4410-998c-e4087938db96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 0.10844002432247225\n",
      "Mean Absolute Error (MAE): 0.080826294876816\n",
      "Mean Squared Error (MSE): 0.011759238875058375\n",
      "R-squared (R2): 0.2627283689203407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bala4\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data from CSV file\n",
    "file_path = \"C:/Users/bala4/OneDrive/Pictures/student prediction/overall preprocessing.csv\"  # Replace with the path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Manually specify features (X) and labels (y)\n",
    "X = df[['vaild', 'correctsub', 'incorrectsub', 'compileerror', 'timespent', 'editdistance']]\n",
    "y = df['score']\n",
    "\n",
    "# Identify and handle NaN values (dropping rows for this example)\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Impute missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Define base models with hyperparameters\n",
    "knn_model = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=20))  # Adjust n_neighbors as needed\n",
    "svm_model = make_pipeline(StandardScaler(), SVR(C=1.0, kernel='rbf'))  # Adjust C and kernel as needed\n",
    "xgboost_model = XGBRegressor(learning_rate=0.1, n_estimators=100, max_depth=6)  # Adjust parameters as needed\n",
    "\n",
    "# Define the meta-model (linear regression)\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Create the stacked regression model\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=[('knn', knn_model), ('svm', svm_model), ('xgboost', xgboost_model)],\n",
    "    final_estimator=meta_model\n",
    ")\n",
    "\n",
    "# Fit the stacked model on the training data\n",
    "stacked_model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = stacked_model.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the performance of the stacked model\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # RMSE\n",
    "mae = mean_absolute_error(y_test, y_pred)  # MAE\n",
    "mse = mean_squared_error(y_test, y_pred)  # MSE\n",
    "r2 = r2_score(y_test, y_pred)  # R2\n",
    "\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'R-squared (R2): {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae8b5a2-9d28-4bda-bf34-d1bf85abc576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
